{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
       "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
       "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
       "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
       "\n",
       "    ca  thal  num  \n",
       "0  0.0   6.0    0  \n",
       "1  3.0   3.0    2  \n",
       "2  2.0   7.0    1  \n",
       "3  0.0   3.0    0  \n",
       "4  0.0   3.0    0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "heart_disease = fetch_ucirepo(id=45) \n",
    "  \n",
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame(heart_disease.data.original) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente mostrando que o nosso problema de classificação se encaixa num problema multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num\n",
       "0    164\n",
       "1     55\n",
       "2     36\n",
       "3     35\n",
       "4     13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['num'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 classes diferentes para cada instância, representando:<br>\n",
    "    - 0 para nenhuma doença cardíaca<br>\n",
    "    - 1 a 4 para diferentes doenças cardíacas\n",
    "\n",
    "DADOS DESBALANCEADOS !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apenas tratando valores ausentes!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    float64\n",
      " 1   sex       303 non-null    float64\n",
      " 2   cp        303 non-null    float64\n",
      " 3   trestbps  303 non-null    float64\n",
      " 4   chol      303 non-null    float64\n",
      " 5   fbs       303 non-null    float64\n",
      " 6   restecg   303 non-null    float64\n",
      " 7   thalach   303 non-null    float64\n",
      " 8   exang     303 non-null    float64\n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    float64\n",
      " 11  ca        303 non-null    float64\n",
      " 12  thal      303 non-null    float64\n",
      " 13  num       303 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "dtypes = data.dtypes\n",
    "columns = data.columns # Salvando as colunas da base de dados\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "data = imp.fit_transform(data)\n",
    "data = pd.DataFrame(data, columns=columns)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apenas separando em x e y, também separando conjunto de treinamento e de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
      "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
      "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
      "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
      "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
      "\n",
      "   slope   ca  thal  \n",
      "0    3.0  0.0   6.0  \n",
      "1    2.0  3.0   3.0  \n",
      "2    2.0  2.0   7.0  \n",
      "3    3.0  0.0   3.0  \n",
      "4    1.0  0.0   3.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data (as pandas dataframes) \n",
    "y = data['num']\n",
    "x = data.drop(columns=['num'])\n",
    "print(x.head())\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(\n",
    "#     x, \n",
    "#     y, \n",
    "#     test_size=0.3, \n",
    "#     random_state=0, \n",
    "#     shuffle=True, \n",
    "#     stratify=y\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desempenho de algoritmos inerentemente multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dani/ciencias-da-computacao/8-semestre/mineracao-de-dados/atividade-1/venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dani/ciencias-da-computacao/8-semestre/mineracao-de-dados/atividade-1/venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dani/ciencias-da-computacao/8-semestre/mineracao-de-dados/atividade-1/venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dani/ciencias-da-computacao/8-semestre/mineracao-de-dados/atividade-1/venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dani/ciencias-da-computacao/8-semestre/mineracao-de-dados/atividade-1/venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Modelo  Acurácia  F1 Macro  F1 Weighted\n",
      "0          Tree  0.495050  0.293748     0.496732\n",
      "1       Bagging  0.528053  0.273287     0.504783\n",
      "2   AdaBoosting  0.498350  0.271768     0.500225\n",
      "3  RandomForest  0.580858  0.292685     0.531037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "metrics = []\n",
    "models = {\n",
    "    \"Tree\": DecisionTreeClassifier(random_state=0),\n",
    "    \"Bagging\": BaggingClassifier(random_state=0),\n",
    "    \"AdaBoosting\": AdaBoostClassifier(random_state=0),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=0)\n",
    "}\n",
    "\n",
    "\n",
    "for model_name, model in models.items():\n",
    "\n",
    "    # Estratificando conjunto de dados\n",
    "    skf = StratifiedKFold(n_splits=5) # 5 pois o conjunto de dados é desbalanceado\n",
    "\n",
    "    y_pred = cross_val_predict(model, x, y, cv=skf)\n",
    "\n",
    "     # Calcular as métricas\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1_macro = f1_score(y, y_pred, average='macro')\n",
    "    f1_weighted = f1_score(y, y_pred, average='weighted')\n",
    "    \n",
    "    # Armazenar os resultados em uma lista\n",
    "    metrics.append({\n",
    "        \"Modelo\": model_name,\n",
    "        \"Acurácia\": accuracy,\n",
    "        \"F1 Macro\": f1_macro,\n",
    "        \"F1 Weighted\": f1_weighted\n",
    "    })\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "print(df_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melhor algoritmo para a nossa base de dados: RandomForest !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunando hiper-parâmetros de um RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=10, min_samples_leaf=np.int64(1),\n",
      "                       min_samples_split=np.int64(6), n_estimators=10,\n",
      "                       random_state=0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Definindo os hiperparâmetros para o Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 20, 50],  # Número de árvores\n",
    "    'max_depth': [None, 10, 20, 30],  # Profundidade máxima\n",
    "    'min_samples_split': np.arange(2, 11),  # Split mínimo\n",
    "    'min_samples_leaf': np.arange(1, 5),  # Folhas mínimas\n",
    "    'max_features': [None, 'sqrt', 'log2']  # Máximos recursos para split\n",
    "}\n",
    "\n",
    "# Usando múltiplas métricas\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'f1_macro': make_scorer(f1_score, average='macro'),\n",
    "    'f1_weighted': make_scorer(f1_score, average='weighted')\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    rfc, \n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    cv=skf,\n",
    "    refit='f1_macro', # por se tratar de um dataset desbalanceado, não usamos média ponderada\n",
    "    n_jobs=-1\n",
    ")\n",
    "# Ajustar o GridSearchCV\n",
    "model_rf = grid_search.fit(x, y) \n",
    "\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Parâmetros  Acurácia (Média)  \\\n",
      "0     {'max_depth': None, 'max_features': None, 'min...          0.547760   \n",
      "1     {'max_depth': None, 'max_features': None, 'min...          0.540984   \n",
      "2     {'max_depth': None, 'max_features': None, 'min...          0.577268   \n",
      "3     {'max_depth': None, 'max_features': None, 'min...          0.560710   \n",
      "4     {'max_depth': None, 'max_features': None, 'min...          0.570710   \n",
      "...                                                 ...               ...   \n",
      "1723  {'max_depth': 30, 'max_features': 'log2', 'min...          0.600492   \n",
      "1724  {'max_depth': 30, 'max_features': 'log2', 'min...          0.580874   \n",
      "1725  {'max_depth': 30, 'max_features': 'log2', 'min...          0.564317   \n",
      "1726  {'max_depth': 30, 'max_features': 'log2', 'min...          0.577486   \n",
      "1727  {'max_depth': 30, 'max_features': 'log2', 'min...          0.593934   \n",
      "\n",
      "      Acurácia (Desvio)  F1 Macro (Média)  F1 Macro (Desvio)  \\\n",
      "0              0.023924          0.268430           0.022980   \n",
      "1              0.057620          0.260317           0.056591   \n",
      "2              0.055838          0.299385           0.045822   \n",
      "3              0.047141          0.287257           0.046940   \n",
      "4              0.052865          0.297843           0.052928   \n",
      "...                 ...               ...                ...   \n",
      "1723           0.026680          0.289495           0.037407   \n",
      "1724           0.024327          0.313015           0.057767   \n",
      "1725           0.045451          0.271134           0.056612   \n",
      "1726           0.018135          0.246614           0.033541   \n",
      "1727           0.031926          0.273197           0.045880   \n",
      "\n",
      "      F1 Weighted (Média)  F1 Weighted (Desvio)  \n",
      "0                0.507682              0.012164  \n",
      "1                0.498851              0.053914  \n",
      "2                0.540387              0.051571  \n",
      "3                0.527863              0.048893  \n",
      "4                0.540289              0.052424  \n",
      "...                   ...                   ...  \n",
      "1723             0.522484              0.033610  \n",
      "1724             0.527925              0.031175  \n",
      "1725             0.501834              0.050643  \n",
      "1726             0.498958              0.023580  \n",
      "1727             0.515192              0.035268  \n",
      "\n",
      "[1728 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extrair os resultados da grid_search\n",
    "results = grid_search.cv_results_\n",
    "\n",
    "# Criar o DataFrame com as colunas desejadas\n",
    "df_results = pd.DataFrame({\n",
    "    'Parâmetros': results['params'],\n",
    "    'Acurácia (Média)': results['mean_test_accuracy'],\n",
    "    'Acurácia (Desvio)': results['std_test_accuracy'],\n",
    "    'F1 Macro (Média)': results['mean_test_f1_macro'],\n",
    "    'F1 Macro (Desvio)': results['std_test_f1_macro'],\n",
    "    'F1 Weighted (Média)': results['mean_test_f1_weighted'],\n",
    "    'F1 Weighted (Desvio)': results['std_test_f1_weighted']\n",
    "})\n",
    "\n",
    "# Exibir o DataFrame para visualizar os resultados\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=10, min_samples_leaf=np.int64(1),\n",
      "                       min_samples_split=np.int64(6), n_estimators=10,\n",
      "                       random_state=0)\n",
      "{'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': np.int64(1), 'min_samples_split': np.int64(6), 'n_estimators': 10}\n",
      "0.35711714007383877\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Modelo  Acurácia  F1 Macro  F1 Weighted\n",
      "0                Tree  0.495050  0.293748     0.496732\n",
      "1             Bagging  0.528053  0.273287     0.504783\n",
      "2         AdaBoosting  0.498350  0.271768     0.500225\n",
      "3        RandomForest  0.580858  0.292685     0.531037\n",
      "4  Tuned RandomForest  0.617162  0.375294     0.577266\n"
     ]
    }
   ],
   "source": [
    "best_params = grid_search.best_params_\n",
    "\n",
    "rf_best = RandomForestClassifier(**best_params, random_state=0)\n",
    "\n",
    "# Usar validação cruzada para obter previsões com cross_val_predict\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "y_pred = cross_val_predict(rf_best, x, y, cv=skf)\n",
    "\n",
    "# Avaliar o modelo com as métricas desejadas\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "f1_macro = f1_score(y, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y, y_pred, average='weighted')\n",
    "\n",
    "metrics.append({\n",
    "        \"Modelo\": \"Tuned RandomForest\",\n",
    "        \"Acurácia\": accuracy,\n",
    "        \"F1 Macro\": f1_macro,\n",
    "        \"F1 Weighted\": f1_weighted\n",
    "})\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "print(df_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tunagem de hiper-parâmetros melhorou a nossa RandomForest em todas as métricas, entretanto, esperava mais, a busca de hiper-parâmetros demorou 3 minutos e mais de 1500 modelos foram testados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OVO com Árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Modelo  Acurácia  F1 Macro  F1 Weighted\n",
      "0                Tree  0.495050  0.293748     0.496732\n",
      "1             Bagging  0.528053  0.273287     0.504783\n",
      "2         AdaBoosting  0.498350  0.271768     0.500225\n",
      "3        RandomForest  0.580858  0.292685     0.531037\n",
      "4  Tuned RandomForest  0.617162  0.375294     0.577266\n",
      "5            OneVsOne  0.521452  0.339700     0.536474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "ovo_tree = OneVsOneClassifier(\n",
    "    DecisionTreeClassifier(random_state=0)\n",
    ")\n",
    "\n",
    "# Usar validação cruzada para obter previsões com cross_val_predict\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "y_pred = cross_val_predict(ovo_tree, x, y, cv=skf)\n",
    "\n",
    "# Avaliar o modelo com as métricas desejadas\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "f1_macro = f1_score(y, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y, y_pred, average='weighted')\n",
    "\n",
    "metrics.append({\n",
    "        \"Modelo\": \"OneVsOne\",\n",
    "        \"Acurácia\": accuracy,\n",
    "        \"F1 Macro\": f1_macro,\n",
    "        \"F1 Weighted\": f1_weighted\n",
    "})\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "print(df_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Modelo  Acurácia  F1 Macro  F1 Weighted\n",
      "0                Tree  0.495050  0.293748     0.496732\n",
      "1             Bagging  0.528053  0.273287     0.504783\n",
      "2         AdaBoosting  0.498350  0.271768     0.500225\n",
      "3        RandomForest  0.580858  0.292685     0.531037\n",
      "4  Tuned RandomForest  0.617162  0.375294     0.577266\n",
      "5            OneVsOne  0.521452  0.339700     0.536474\n",
      "6            OneVsAll  0.369637  0.225109     0.412288\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "ova_tree = OneVsRestClassifier(\n",
    "    DecisionTreeClassifier(random_state=0)\n",
    ")\n",
    "\n",
    "# Usar validação cruzada para obter previsões com cross_val_predict\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "y_pred = cross_val_predict(ova_tree, x, y, cv=skf)\n",
    "\n",
    "# Avaliar o modelo com as métricas desejadas\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "f1_macro = f1_score(y, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y, y_pred, average='weighted')\n",
    "\n",
    "metrics.append({\n",
    "        \"Modelo\": \"OneVsAll\",\n",
    "        \"Acurácia\": accuracy,\n",
    "        \"F1 Macro\": f1_macro,\n",
    "        \"F1 Weighted\": f1_weighted\n",
    "})\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "print(df_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A RandomForest tunada ainda foi a melhor estratégia visando o nosso dataset\n",
    "<br>\n",
    "<br>\n",
    "OVO se saiu considerávelmente melhor do que OVA em todas as medidas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
